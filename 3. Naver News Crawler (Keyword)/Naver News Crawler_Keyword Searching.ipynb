{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네이버 뉴스 크롤러"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 키워드 입력시, 키워드에 해당하는 뉴스기사 크롤링\n",
    "- 페이지 설정 가능\n",
    "- 크롤링 한 뉴스기사 모아서, 단어 빈도수 Counting\n",
    "- 상위 30개 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 크롤러_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword : 부동산\n",
      "page (0 ~ ): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('분양', 32),\n",
       " ('상한', 29),\n",
       " ('주택', 25),\n",
       " ('사업', 20),\n",
       " ('개발', 19),\n",
       " ('시행', 18),\n",
       " ('국토', 17),\n",
       " ('연구원', 17),\n",
       " ('분석', 16),\n",
       " ('서울', 16),\n",
       " ('하락', 15),\n",
       " ('만주', 15),\n",
       " ('금리', 14),\n",
       " ('가격', 13),\n",
       " ('정부', 13),\n",
       " ('시장', 13),\n",
       " ('집값', 12),\n",
       " ('조선', 11),\n",
       " ('지역', 11),\n",
       " ('대박', 11),\n",
       " ('재건축', 10),\n",
       " ('투자', 10),\n",
       " ('증가', 10),\n",
       " ('자산', 10),\n",
       " ('규제', 10),\n",
       " ('택배', 10),\n",
       " ('수도권', 9),\n",
       " ('확대', 9),\n",
       " ('효과', 9),\n",
       " ('아파트', 9)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "from konlpy.tag import Twitter\n",
    "from konlpy.tag import Kkma\n",
    "from collections import Counter\n",
    "import jpype\n",
    "import pandas\n",
    "\n",
    "\n",
    "si_dong = input(\"keyword : \")\n",
    "page = int(input(\"page (0 ~ ): \")) -1\n",
    "\n",
    "ua = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.87 Safari/537.36'}\n",
    "\n",
    "urls = []\n",
    "for page in range(1, page + 1):\n",
    "    url = \"https://search.naver.com/search.naver?&where=news&query={}&sm=tab_pge&sort=1&photo=0&field=0&reporter_article=&pd=0&ds=&de=&docid=&nso=so:dd,p:all,a:all&mynews=0&start={}1&refresh_start=0\".format(si_dong,page)\n",
    "\n",
    "    response = requests.get(url, headers = ua)\n",
    "    html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    li_list = html.select(\"ul.type01 li\")\n",
    "\n",
    "    for li in li_list:\n",
    "        ul = li.select_one('dl dd a').get('href')\n",
    "        if ul == '#':\n",
    "            pass\n",
    "        else:\n",
    "            urls.append(ul)\n",
    "    time.sleep(1)\n",
    "\n",
    "def refine_text(text):\n",
    "    text = text.replace(\"\\n\",\"\").replace(\"\\t\",\"\").replace(\"\\r\",\"\").replace('// flash 오류를 우회하기 위한 함수 추가','')\n",
    "    text = text.replace('function _flash_removeCallback() {}','').replace('“','').replace(\"”\",'')\n",
    "    text = text.replace('‘','').replace(\"’\",'').replace('\"','').replace(\"'\",'').replace('  ','')\n",
    "    text = text.replace('인턴기자','').replace('기자','').replace('뉴스','')\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "news = ''\n",
    "\n",
    "for ul in urls:\n",
    "    response = requests.get(ul, headers = ua)\n",
    "    html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    html.select_one(\"#content div.end_ct_area\")\n",
    "    \n",
    "    try:\n",
    "        body = refine_text(html.select_one(\"#articleBodyContents\").text).split('@')[0]\n",
    "    except:\n",
    "        continue\n",
    "    body = body.split('▶')[0]\n",
    "    body = body.split('▲')[0]\n",
    "    body = body.split('◇')[0]\n",
    "    body = re.sub(r'\\(.*?\\)',\"\",body)\n",
    "    body = re.sub(r'\\[.*?\\]',\"\",body)\n",
    "    body = re.sub(r'\\【.*?\\】',\"\",body)\n",
    "    body = body[:-15].strip().replace('(','')\n",
    "    news += body\n",
    "\n",
    "kkma = Kkma()\n",
    "twitter = Twitter()\n",
    "\n",
    "nouns = twitter.nouns(news)\n",
    "\n",
    "wdlist = []\n",
    "for i in range(0,len(nouns)):\n",
    "    if (len(nouns[i])) >= 2 and nouns[i] != si_dong and nouns[i] != si_dong[:-1]:\n",
    "        wdlist.append(nouns[i])\n",
    "\n",
    "wc = Counter(wdlist)       # 각 단어별 빈도수 측정\n",
    "\n",
    "wc.most_common(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
